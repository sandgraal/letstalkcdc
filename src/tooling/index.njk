---
layout: base.njk
title: "CDC Tooling Comparison | CDC: The Missing Manual"
canonicalPath: "/tooling/"
head_extra: |
  <meta
        content="A comparison of CDC tools and platforms, including open-source (Debezium), managed cloud services (AWS DMS), and commercial enterprise solutions (Fivetran, GoldenGate)."
        name="description"
      />
      <link href="/assets/css/styles.css" rel="stylesheet" />
scripts: |
  <script type="module">
        const apply = (m) => (document.documentElement.dataset.theme = m);
        const saved = localStorage.getItem("theme");
        const prefersDark = matchMedia("(prefers-color-scheme: dark)").matches;
        apply(saved ?? (prefersDark ? "dark" : "light"));
        document.addEventListener("click", (e) => {
          if (e.target.matches("[data-toggle-theme]")) {
            const next =
              document.documentElement.dataset.theme === "dark"
                ? "light"
                : "dark";
            apply(next);
            localStorage.setItem("theme", next);
          }
        });
      </script>
---
<h1>The Modern CDC Toolkit: A Platform Comparison</h1>
      <article class="prose">
        <p>
          The market for Change Data Capture tools has matured significantly,
          offering a range of solutions that cater to different needs. Choosing
          the right tool involves balancing control, cost, and convenience.
        </p>

        <h2 id="open-source">Open-Source Champions: Power and Flexibility</h2>
        <p>
          Open-source tools are favored by organizations with strong in-house
          data engineering capabilities that require deep customization and want
          to avoid vendor lock-in.
        </p>
        <h3>Debezium</h3>
        <p>
          Debezium has emerged as the de facto open-source standard for
          log-based CDC. It is a distributed platform of connectors that runs on
          the Apache Kafka Connect framework, providing high-performance,
          low-latency connectors for a wide range of popular databases.
        </p>
        <ul>
          <li>
            <strong>Pros:</strong> Free to use (Apache 2.0 license), highly
            flexible, robust feature set, and backed by a large community.
          </li>
          <li>
            <strong>Cons:</strong> The primary challenge is operational
            complexity. It requires users to deploy, manage, scale, and monitor
            the underlying infrastructure, including Kafka and Kafka Connect,
            which requires significant technical expertise.
          </li>
        </ul>

        <h3>Airbyte (OSS core + Cloud)</h3>
        <p>
          Airbyte provides a large connector catalog (including CDC connectors)
          with an OSS core and a hosted “Cloud” offering. CDC depth varies by
          source; many pipelines are log-based, others are polling.
        </p>
        <ul>
          <li>
            <strong>Pros:</strong> Broad connector coverage; easy to get
            started; active ecosystem.
          </li>
          <li>
            <strong>Cons:</strong> Operational polish and CDC fidelity depend on
            the specific connector; long-running streaming jobs may need tuning.
          </li>
        </ul>

        <h3>Maxwell’s Daemon (MySQL)</h3>
        <p>
          A lightweight MySQL binlog tailer that emits JSON change events to
          Kafka/Kinesis. Simpler than Debezium but focused on MySQL only.
        </p>
        <ul>
          <li>
            <strong>Pros:</strong> Small footprint, easy to run for MySQL-only
            stacks.
          </li>
          <li>
            <strong>Cons:</strong> Narrow scope; fewer enterprise features
            (schema registry integration, snapshots, etc.).
          </li>
        </ul>
        <h2 id="managed-cloud">
          Fully Managed Cloud Services: Simplicity and Integration
        </h2>
        <p>
          Cloud providers offer managed CDC services that abstract away the
          complexity of infrastructure management, allowing teams to set up data
          pipelines quickly.
        </p>
        <h3>AWS Database Migration Service (DMS)</h3>
        <p>
          AWS DMS is a fully managed service that supports a wide variety of
          migrations and replications. It can capture changes from sources like
          Oracle, PostgreSQL, and SQL Server and deliver them to targets across
          the AWS ecosystem, such as Amazon S3 and Redshift.
        </p>
        <ul>
          <li>
            <strong>Pros:</strong> Its main advantages are simplicity and deep
            integration with the AWS ecosystem. It has a pay-as-you-go pricing
            model and eliminates the need for users to manage any underlying
            servers or software.
          </li>
          <li>
            <strong>Cons:</strong> Performance can be variable, and it is
            primarily designed for use within the AWS ecosystem, which can lead
            to vendor lock-in. It can also have limitations regarding the
            capture of certain database features or DDL changes.
          </li>
        </ul>

        <h3>Google Cloud Datastream</h3>
        <p>
          Serverless, log-based CDC into Google Cloud (BigQuery, Cloud SQL,
          GCS). Integrates with Dataflow templates for transformations and
          Warehouse MERGE patterns.
        </p>
        <ul>
          <li>
            <strong>Pros:</strong> Low-ops, serverless scale; smooth handoff to
            BigQuery.
          </li>
          <li>
            <strong>Cons:</strong> Best inside GCP; feature gaps for certain
            sources/DDL.
          </li>
        </ul>

        <h3>Azure (ADF/Synapse) with CDC</h3>
        <p>
          Azure Data Factory / Synapse pipelines support change capture for SQL
          Server/Azure SQL and integration with Event Hubs & Data Lake for
          downstream processing.
        </p>
        <ul>
          <li>
            <strong>Pros:</strong> Native Azure integration; quick path to
            Synapse/Lake.
          </li>
          <li>
            <strong>Cons:</strong> Mixed CDC depth across sources; tuning needed
            for low-latency needs.
          </li>
        </ul>

        <h3>Confluent Cloud (Managed Connect + Debezium)</h3>
        <p>
          Managed Kafka Connect with official Debezium-based source connectors
          and schema registry. Reduces the ops burden of running Connect while
          keeping the open-source connector model.
        </p>
        <ul>
          <li>
            <strong>Pros:</strong> Paved-road operations (scaling, monitoring,
            upgrades) for Connect/Registry.
          </li>
          <li>
            <strong>Cons:</strong> Still requires Kafka mental model; priced as
            a managed platform.
          </li>
        </ul>
        <h2 id="commercial">
          Commercial Enterprise Platforms: Support and Scale
        </h2>
        <p>
          A number of commercial vendors offer polished, enterprise-grade CDC
          platforms that provide end-to-end solutions with dedicated support and
          guaranteed SLAs.
        </p>
        <ul>
          <li>
            <strong>Oracle GoldenGate:</strong> A long-standing leader in data
            replication, known for high performance and reliability, especially
            in Oracle environments.
          </li>
          <li>
            <strong>Fivetran:</strong> A modern, cloud-native ELT platform
            celebrated for its ease of use and a massive library of pre-built
            connectors. Its consumption-based pricing can become costly at high
            volumes.
          </li>
          <li>
            <strong>Striim:</strong> A unified platform that combines CDC with
            real-time, in-flight stream processing and analytics, focused on
            powering operational use cases that demand sub-second latency.
          </li>
          <li>
            <strong>Qlik Replicate (formerly Attunity):</strong> An
            enterprise-grade solution known for its broad platform support and
            an intuitive graphical user interface that simplifies replication
            tasks.
          </li>
          <li>
            <strong>Precisely (formerly HVR):</strong> High-performance
            log-based replication with strong Oracle/SQL Server coverage and
            enterprise controls.
          </li>
        </ul>

        <h2 id="comparison-table">High-Level Tooling Comparison</h2>
        <p>
          This table provides a strategic comparison of representative tools
          from each category.
        </p>
        <div class="table-container">
          <table>
            <thead>
              <tr>
                <th>Feature</th>
                <th>Debezium (Open-Source)</th>
                <th>AWS DMS (Managed Cloud)</th>
                <th>Fivetran (Commercial SaaS)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td><strong>Deployment Model</strong></td>
                <td>
                  Self-hosted. Requires user to manage Kafka, Kafka Connect, and
                  connectors.
                </td>
                <td>Fully managed service within the AWS cloud.</td>
                <td>Fully managed, multi-cloud SaaS platform.</td>
              </tr>
              <tr>
                <td><strong>Core Technology</strong></td>
                <td>
                  Open-source, log-based connectors built for Apache Kafka.
                </td>
                <td>Proprietary replication technology managed by AWS.</td>
                <td>
                  Proprietary, log-based CDC technology, fully abstracted from
                  the user.
                </td>
              </tr>
              <tr>
                <td><strong>Primary Use Case</strong></td>
                <td>
                  Building flexible, custom event-driven architectures and data
                  pipelines.
                </td>
                <td>
                  Database migrations and data replication primarily within the
                  AWS ecosystem.
                </td>
                <td>
                  Automated, no-code ELT pipelines to cloud data warehouses and
                  data lakes.
                </td>
              </tr>
              <tr>
                <td><strong>Cost Model</strong></td>
                <td>
                  Free (Apache 2.0 license). Incurs infrastructure and
                  operational costs.
                </td>
                <td>
                  Pay-as-you-go (per hour for the replication instance and log
                  storage).
                </td>
                <td>
                  Consumption-based (Monthly Active Rows). Can become expensive
                  at high scale.
                </td>
              </tr>
              <tr>
                <td><strong>Best For</strong></td>
                <td>
                  Teams with strong data engineering and Kafka expertise seeking
                  maximum control and zero licensing fees.
                </td>
                <td>
                  Teams heavily invested in AWS seeking simplicity, speed of
                  deployment, and tight cloud integration.
                </td>
                <td>
                  Teams of any size wanting a hands-off, fully managed solution
                  with broad connector support and minimal setup.
                </td>
              </tr>
            </tbody>
          </table>
        </div>
        <h2 id="capabilities">What to check before you choose</h2>
        <ul>
          <li>
            <strong>Source coverage &amp; method:</strong> true log-based vs
            polling; snapshot modes (initial, incremental, resume).
          </li>
          <li>
            <strong>DDL behavior:</strong> adds/renames/drops; online schema
            change support; registry compatibility modes.
          </li>
          <li>
            <strong>Delivery semantics:</strong> ALO by default; EOS
            <em>scope</em> (Kafka-only transactions vs idempotent sinks for
            external warehouses).
          </li>
          <li>
            <strong>Exactly-once at the sink:</strong> MERGE/UPSERT patterns,
            staging+MERGE, dedupe tables.
          </li>
          <li>
            <strong>Ops &amp; observability:</strong> lag/backlog metrics, DLQs,
            replay/rewind, upgrade path.
          </li>
          <li>
            <strong>Multi-tenancy &amp; cost:</strong> topic/partition math,
            RF/retention, egress/storage pricing, chargeback/quota features.
          </li>
          <li>
            <strong>Security &amp; governance:</strong> PII masking, field-level
            filters, RBAC/ACLs, encryption, private networking.
          </li>
        </ul>

        <h2 id="gotchas">Common gotchas (agnostic to vendor)</h2>
        <ul>
          <li>
            <strong>Log retention bloat:</strong> paused/broken connectors can
            block WAL/binlog/T-log cleanup—alert on backlog age.
          </li>
          <li>
            <strong>Schema drift:</strong> without a registry + policies,
            producers break consumers; enforce compatibility.
          </li>
          <li>
            <strong>Polling CDC deletions:</strong> hard deletes aren’t
            visible—add soft-delete markers or change tables.
          </li>
          <li>
            <strong>Global ordering myths:</strong> CDC preserves per-key order,
            not cross-entity total order.
          </li>
          <li>
            <strong>Warehouse costs:</strong> too-frequent small MERGEs are
            expensive—batch micro-windows without violating freshness SLOs.
          </li>
        </ul>
      </article>
      <div class="pagination">
        <a href="strategy/">← Back: Strategic Value</a>
      </div>
