---
layout: base.njk
title: "First 15 Minutes — CDC Troubleshooting"
canonicalPath: "/troubleshooting/"
head_extra: |
  <meta
        content="A repeatable first-15-minutes playbook to triage change data capture incidents across Postgres, MySQL, Oracle, Kafka/Debezium, and common sinks."
        name="description"
      />
            <link rel="stylesheet" href="{{ '/assets/css/pages/troubleshooting.css' | url }}">

---
<!-- The .prose class now wraps only the introductory text -->
      <div class="prose">
        <h1>First 15 Minutes: CDC Troubleshooting</h1>
        <p class="muted">
          A repeatable triage to stabilize incidents fast. Keep it pragmatic,
          measurable, and reversible.
        </p>
      </div>

      <!-- The multi-column sections are now outside the .prose wrapper -->
      <section class="box callout">
        <h2>Quick Triage (5–8 minutes)</h2>
        <ol>
          <li>
            <strong>Freeze changes</strong> that make state drift: pause
            backfills, schema changes, and connector restarts.
          </li>
          <li>
            <strong>Define the failure mode</strong>: <em>stuck</em> (no
            progress), <em>slow</em> (lag growing), <em>wrong</em> (duplicates,
            missing rows), or <em>crashing</em>.
          </li>
          <li>
            <strong>Bound the blast radius</strong>: single table/tenant vs
            global; snapshot vs stream.
          </li>
          <li>
            <strong>Checkpoint evidence</strong> (timestamps, connector name,
            offsets, group id). Don’t tail logs without writing down the top
            lines you see.
          </li>
          <li>
            <strong>Choose a safety</strong>: if logs are at risk of rotating
            out, extend retention (WAL/binlog/redo) before touching the
            pipeline.
          </li>
        </ol>
        <p class="muted">
          Goal: stop data loss, capture proof, buy time. Detailed checks below.
        </p>
      </section>
      <section class="two">
        <div class="box">
          <h2>Artifacts to Collect (Copy/Paste)</h2>
          <ul class="checklist">
            <li>
              Versions: source db, connector (Debezium), broker
              (Kafka/Redpanda), sink
            </li>
            <li>
              Connector config (sanitized): include snapshot mode,
              includes/excludes, heartbeat
            </li>
            <li>Exact error lines: 20–50 lines around the first failure</li>
            <li>
              Lag/offsets: consumer group lag and last committed LSN/GTID/SCN
            </li>
            <li>
              Log retention settings: WAL/binlog/redo retention and current
              oldest log
            </li>
          </ul>
          <details open="">
            <summary><strong>Commands</strong></summary>
            <p><span class="pill">Kafka (Consumer Lag)</span></p>
            <pre><button class="copy">copy</button><code>kafka-consumer-groups --bootstrap-server &lt;host:port&gt; \
  --describe --group &lt;your-sink-group&gt;</code></pre>
            <p><span class="pill">Connect (Connector Status)</span></p>
            <pre><button class="copy">copy</button><code>curl -s http://&lt;connect-host:8083&gt;/connectors | jq
curl -s http://&lt;connect-host:8083&gt;/connectors/&lt;name&gt;/status | jq</code></pre>
          </details>
        </div>
        <div class="box">
          <h2>Stabilize First</h2>
          <ul class="checklist">
            <li>
              Ensure source logs retained ≥ time to fix + snapshot duration
            </li>
            <li>Enable DLQ (or equivalent) to prevent silent drops</li>
            <li>
              Reduce parallelism if source is choking (snapshot &amp; stream
              task counts)
            </li>
            <li>
              If duplicates are appearing, convert sink writes to
              <em>idempotent</em> upserts (MERGE/UPSERT) immediately
            </li>
          </ul>
        </div>
      </section>
      <section class="grid">
        <div class="box">
          <h2>Postgres Quick Checks</h2>
          <details open="">
            <summary><strong>Configuration + Health</strong></summary>
            <pre><button class="copy">copy</button><code>-- WAL &amp; slots
SHOW wal_level;                -- should be 'logical'
SHOW max_wal_senders;          -- &gt;= number of replication clients
SHOW max_replication_slots;    -- &gt;= slots in use
SELECT slot_name, active, restart_lsn, confirmed_flush_lsn
FROM pg_replication_slots;

-- retention &amp; pressure
SHOW wal_keep_size;            -- size hint for retained WAL
SELECT now() - pg_last_wal_replay_lsn()::text::pg_lsn; -- on standby

-- lag (if using logical slot)
SELECT pg_size_pretty(pg_wal_lsn_diff(pg_current_wal_lsn(), restart_lsn)) AS retained_from_slot
FROM pg_replication_slots WHERE slot_name='&lt;slot&gt;';</code></pre>
          </details>
          <details>
            <summary><strong>Common Symptoms → First Aid</strong></summary>
            <ul>
              <li>
                <em>Snapshot stalls:</em> reduce fetch size; whitelist fewer
                tables; ensure long-running txns aren’t blocking.
              </li>
              <li>
                <em>Slot disk pressure:</em> sink caught behind → raise sink
                throughput or pause snapshot; never drop the slot without a
                plan.
              </li>
              <li>
                <em>Missing updates:</em> replica identity not full on keyless
                tables → set <code>REPLICA IDENTITY FULL</code> where needed.
              </li>
            </ul>
          </details>
        </div>
        <div class="box">
          <h2>MySQL Quick Checks</h2>
          <details open="">
            <summary><strong>Configuration + Health</strong></summary>
            <pre><button class="copy">copy</button><code>-- binlog mode
SHOW VARIABLES LIKE 'binlog_format';       -- should be ROW
SHOW VARIABLES LIKE 'binlog_row_image';    -- FULL or MINIMAL (know your connector's needs)
SHOW VARIABLES LIKE 'gtid_mode';           -- ON preferred
SHOW MASTER STATUS;                         -- file/pos + executed GTID set

-- retention (8.0+)
SHOW VARIABLES LIKE 'binlog_expire_logs_seconds';

-- heartbeat/throughput
SHOW GLOBAL STATUS LIKE 'Binlog_cache_disk_use';</code></pre>
          </details>
          <details>
            <summary><strong>Common Symptoms → First Aid</strong></summary>
            <ul>
              <li>
                <em>Duplicates after restart:</em> sink not idempotent → change
                inserts to MERGE/UPSERT with stable pk + version.
              </li>
              <li>
                <em>Lost history:</em> binlogs expired during snapshot → extend
                expire window; restart from fresh snapshot.
              </li>
              <li>
                <em>DDL breakage:</em> add
                <code>include.schema.changes</code> (if supported) and verify
                sink DDL policy.
              </li>
            </ul>
          </details>
        </div>
        <div class="box">
          <h2>Oracle Quick Checks</h2>
          <details open="">
            <summary><strong>Configuration + Health</strong></summary>
            <pre><button class="copy">copy</button><code>-- supplemental logging
SELECT supplemental_log_data_min, supplemental_log_data_all FROM v$database;
-- database log mode
SELECT log_mode FROM v$database;            -- ARCHIVELOG recommended for CDC
-- redo switch &amp; archive status
SELECT sequence#, archived, status FROM v$log ORDER BY first_time DESC FETCH FIRST 5 ROWS ONLY;
-- confirm key columns logging for keyless tables (optional)
SELECT * FROM dba_log_groups WHERE LOG_GROUP_TYPE IN ('ALL COLUMN LOGGING','PRIMARY KEY LOGGING');</code></pre>
          </details>
          <details>
            <summary><strong>Common Symptoms → First Aid</strong></summary>
            <ul>
              <li>
                <em>High redo churn:</em> throttle snapshot/table set; ensure
                filters aren’t too broad.
              </li>
              <li>
                <em>Missed updates:</em> missing supplemental logging for key
                columns → add minimal or table-level logging, resnapshot.
              </li>
              <li>
                <em>Catalog mode mismatch after upgrade:</em> re-check
                connector’s catalog strategy defaults before restart.
              </li>
            </ul>
          </details>
        </div>
        <div class="box">
          <h2>Kafka / Connect Quick Checks</h2>
          <details open="">
            <summary><strong>Status &amp; Lag</strong></summary>
            <pre><button class="copy">copy</button><code># list &amp; inspect
curl -s http://&lt;connect:8083&gt;/connectors | jq
curl -s http://&lt;connect:8083&gt;/connectors/&lt;name&gt;/status | jq

# consumer lag (sink)
kafka-consumer-groups --bootstrap-server &lt;host:port&gt; \
  --describe --group &lt;your-sink-group&gt;

# safe restart of a sick task
curl -s -XPOST http://&lt;connect:8083&gt;/connectors/&lt;name&gt;/tasks/0/restart</code></pre>
          </details>
          <details>
            <summary><strong>Common Symptoms → First Aid</strong></summary>
            <ul>
              <li>
                <em>Connector crash loops:</em> identify first error, enable DLQ
                (<code>errors.tolerance=all</code> + DLQ topic), then fix
                offending table.
              </li>
              <li>
                <em>Slow ingestion:</em> increase tasks up to source limits;
                ensure topic partitions ≥ parallelism; watch sink bottlenecks
                first.
              </li>
              <li>
                <em>Out-of-order within key:</em> ensure producer uses key-aware
                partitioner; keep per-key ordering on the sink merge path.
              </li>
            </ul>
          </details>
        </div>
      </section>
      <section class="box">
        <h2>Sink Verification (Duplicates / Missing Rows)</h2>
        <div class="two">
          <div>
            <h3>Duplicate Primary Keys</h3>
            <pre><button class="copy">copy</button><code>-- generic template (replace table/pk)
SELECT COUNT(*) AS rows,
       COUNT(DISTINCT pk) AS distinct_keys
FROM target_table;</code></pre>
          </div>
          <div>
            <h3>Latest-Wins Check</h3>
            <pre><button class="copy">copy</button><code>-- per business key, do we keep the latest op_ts/version?
SELECT key_col, MAX(op_ts) AS last_ts, COUNT(*) AS events
FROM staging_or_history
GROUP BY key_col
HAVING COUNT(*) &lt;&gt; 1 AND MAX(op_ts) &lt; NOW() - INTERVAL '0 seconds';</code></pre>
          </div>
        </div>
        <p class="muted">
          If duplicates exist, convert the sink write to an idempotent MERGE
          keyed on a stable id + version/op_ts and re-run the last N events.
        </p>
      </section>
      <section class="box callout warn">
        <h2>When to Escalate</h2>
        <ul class="checklist">
          <li>
            Source log gap detected (WAL/binlog/redo missing) and you can’t
            reconstruct from another source → plan a clean resnapshot.
          </li>
          <li>
            Schema/key change incompatible with current sink merge logic →
            schedule maintenance window for transform + backfill.
          </li>
          <li>
            Security/privileges prevent enabling required logging → involve DBAs
            (don’t keep retrying the connector).
          </li>
        </ul>
      </section>
      <section class="box">
        <h2>Acceptance for “Stabilized”</h2>
        <ul class="checklist">
          <li>
            <input type="checkbox" /> Consumer lag is flat or shrinking for 30
            minutes
          </li>
          <li>
            <input type="checkbox" /> Latest offsets/LSN/GTID/SCN are advancing
          </li>
          <li>
            <input type="checkbox" /> DLQ is empty or only contains triaged,
            expected errors
          </li>
          <li>
            <input type="checkbox" /> Duplicate-PK query shows
            <strong>rows == distinct_keys</strong>
          </li>
          <li>
            <input type="checkbox" /> A controlled connector restart does
            <em>not</em> create new duplicates
          </li>
        </ul>
      </section>
