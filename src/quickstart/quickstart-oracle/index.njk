---
layout: base.njk
title: "Oracle CDC Quickstart | CDC: The Missing Manual"
description: "Oracle CDC quickstart: prerequisites (ARCHIVELOG, supplemental logging), health checks, connector notes, verification, and rollback."
canonicalPath: "/quickstarts/quickstart-oracle/"
permalink: quickstarts/quickstart-oracle/index.html
head_extra: |
  <link rel="stylesheet" href="{{ '/assets/css/pages/quickstart-shared.css' | url }}">
---
{% import "components/ui.njk" as ui %}

{{ ui.hero(heroConfig) | safe }}

<div class="page-wrap prose">
  <section class="box">
    <h2>Prerequisites (DB)</h2>
    <ul class="checklist">
      <li><strong>ARCHIVELOG</strong> mode recommended.</li>
      <li>
        <strong>Supplemental logging</strong> enabled (DB-level minimal; table-level for key columns or ALL for keyless tables).
      </li>
      <li>Redo/archive retention window â‰¥ snapshot + catch-up time.</li>
      <li>Stable primary keys (or table log groups capturing merge keys).</li>
    </ul>
    <ul class="checklist">
      <li>
        ARCHIVELOG mode keeps redo history available so CDC readers can recover. Supplemental logging ensures redo contains key columns to reconstruct before/after images, which is critical when applying updates downstream.
      </li>
    </ul>
    <pre><code>-- archivelog and redo
SELECT log_mode FROM v$database;
SELECT sequence#, archived, status
FROM v$log
ORDER BY first_time DESC FETCH FIRST 5 ROWS ONLY;

-- supplemental logging
SELECT supplemental_log_data_min, supplemental_log_data_all FROM v$database;
SELECT owner, table_name, log_group_name, always, log_group_type
FROM dba_log_groups ORDER BY owner, table_name;</code></pre>
  </section>

  <section class="grid">
    <div class="box">
      <h2>DB Setup (examples)</h2>
      <pre><code>-- table-level log group for keyless merge
ALTER TABLE APP.CUSTOMER ADD LOG GROUP lg_customer_pk (ID) ALWAYS;

-- throttle snapshot scope to avoid redo storms (choose limited tables)
-- and plan off-hours if tables are huge</code></pre>
    </div>
    <div class="box">
      <h2>Connector Notes</h2>
      <ul class="checklist">
        <li>Prefer narrow includes/filters to reduce LogMiner workload.</li>
        <li>Measure redo switch rate before and after snapshot.</li>
        <li>Have a plan for LOBs (exclude or route separately if large).</li>
      </ul>
      <pre><code>{
  "name": "oracle-cdc",
  "config": {
    "connector.class": "io.debezium.connector.oracle.OracleConnector",
    "database.hostname": "oracle",
    "database.port": "1521",
    "database.user": "CDC",
    "database.password": "CDC",
    "database.dbname": "ORCLCDB",
    "database.pdb.name": "ORCLPDB1",
    "topic.prefix": "server1",
    "schema.include.list": "APP",
    "table.include.list": "APP.CUSTOMER",
    "tombstones.on.delete": "false",
    "include.schema.changes": "false",
    "snapshot.mode": "initial",
    "errors.tolerance": "all",
    "errors.deadletterqueue.topic.name": "dlq.oracle"
  }
}</code></pre>
    </div>
  </section>

  <section class="grid">
    <div class="box">
      <h2>Verify</h2>
      <pre><code>-- generate a change
UPDATE APP.CUSTOMER SET EMAIL = EMAIL || '.X' WHERE ROWNUM = 1;

-- redo activity sample
SELECT TO_CHAR(first_time, 'YYYY-MM-DD HH24:MI') AS t, COUNT(*) AS switches
FROM v$log_history
WHERE first_time > SYSDATE - 1/24
GROUP BY TO_CHAR(first_time, 'YYYY-MM-DD HH24:MI');</code></pre>
      <pre><code>kafka-console-consumer --bootstrap-server localhost:29092 \
  --topic server1.APP.CUSTOMER --from-beginning --max-messages 5</code></pre>
    </div>
    <div class="box">
      <h2>Acceptance (target/sink)</h2>
      <ul class="checklist">
        <li>No duplicate PKs after connector restart.</li>
        <li>Latest-wins per key by commit timestamp/SCN.</li>
        <li>DLQ empty or only expected test errors.</li>
      </ul>
      <pre><code>SELECT COUNT(*) AS rows, COUNT(DISTINCT ID) AS distinct_keys
FROM TARGET_CUSTOMERS;</code></pre>
    </div>
  </section>

  <section class="box">
    <h2>Safe Rollback</h2>
    <p>
      Pause the connector and retain archived logs until downstream systems are consistent. If schema or log-group changes are needed, plan a clean re-snapshot of affected tables.
    </p>
  </section>
</div>
