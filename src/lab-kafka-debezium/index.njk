---
layout: base.njk
title: "Hands-On Lab: CDC with Kafka, Debezium, and Postgres | CDC: The Missing Manual"
description: "A step-by-step guide to building a real-time Change Data Capture pipeline using Docker, Postgres, Kafka, and Debezium."
canonicalPath: "/lab-kafka-debezium/"
head_extra: |
  <link rel="stylesheet" href="/assets/css/pages/lab-kafka-debezium.css"">

---
<h1>Hands-On Lab: Kafka + Debezium + Postgres</h1>
        <p class="text-xl text-slate-600">
            In this lab, you'll build a complete, end-to-end Change Data Capture (CDC) pipeline from scratch. We'll use Docker Compose to orchestrate a Postgres database, Kafka, and the Debezium Postgres connector to stream row-level changes in real time.
        </p>

        <section aria-labelledby="prereqs" class="lab-steps">
            <h2 id="prereqs">Prerequisites</h2>
            <ul>
                <li><strong>Docker and Docker Compose:</strong> Ensure they are installed and running on your machine.</li>
                <li><strong>A terminal or command prompt:</strong> Basic familiarity with shell commands.</li>
                <li><strong>cURL or a similar tool:</strong> For interacting with the Kafka Connect REST API.</li>
            </ul>

            <h2 id="setup">Lab Setup</h2>
            <ol>
                <li>
                    <h3>Create Project Directory</h3>
                    <p>Start by creating a new folder for your lab project and navigate into it.</p>
                    <pre><code>mkdir cdc-lab && cd cdc-lab</code></pre>
                </li>
                <li>
                    <h3>Create `docker-compose.yml`</h3>
                    <p>Create a file named <code>docker-compose.yml</code> and paste the following configuration. This file defines all the services we need: Zookeeper, Kafka, Postgres, and Debezium/Connect.</p>
                    <pre><code># docker-compose.yml
version: '3.7'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.0
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:7.3.0
    hostname: kafka
    container_name: kafka
    ports:
      - "9092:9092"
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1

  postgres:
    image: debezium/postgres:14
    hostname: postgres
    container_name: postgres
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=start_data_engineer
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=inventory

  connect:
    image: debezium/connect:2.1
    hostname: connect
    container_name: connect
    ports:
      - "8083:8083"
    depends_on:
      - kafka
      - postgres
    environment:
      BOOTSTRAP_SERVERS: 'kafka:29092'
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: my_connect_configs
      OFFSET_STORAGE_TOPIC: my_connect_offsets
      STATUS_STORAGE_TOPIC: my_connect_statuses
                    </code></pre>
                </li>
                <li>
                    <h3>Start the Services</h3>
                    <p>Open your terminal in the project directory and run the following command to start all the containers.</p>
                    <pre><code>docker-compose up -d</code></pre>
                    <p>It might take a few minutes for all services to become fully operational.</p>
                </li>
                 <li>
                    <h3>Register the Postgres Connector</h3>
                    <p>Once the services are running, we need to tell Debezium to start monitoring our Postgres database. We do this by posting a JSON configuration to the Kafka Connect REST API. Create a file named <code>register-postgres.json</code>:</p>
                    <pre><code>{
  "name": "inventory-connector",
  "config": {
    "connector.class": "io.debezium.connector.postgresql.PostgresConnector",
    "tasks.max": "1",
    "database.hostname": "postgres",
    "database.port": "5432",
    "database.user": "start_data_engineer",
    "database.password": "password",
    "database.dbname": "inventory",
    "database.server.name": "dbserver1",
    "table.include.list": "public.products",
    "plugin.name": "pgoutput"
  }
}</code></pre>
                    <p>Now, post this configuration using cURL:</p>
                    <pre><code>curl -i -X POST -H "Accept:application/json" -H "Content-Type:application/json" localhost:8083/connectors/ -d @register-postgres.json</code></pre>
                    <p>You should receive an HTTP 201 response, indicating success.</p>
                </li>
                 <li>
                    <h3>Create a Table and Insert Data</h3>
                    <p>Let's connect to the Postgres database and create the `products` table that our connector is configured to watch.</p>
                    <pre><code>docker-compose exec -u postgres postgres psql -d inventory -c "CREATE TABLE products (id SERIAL PRIMARY KEY, name VARCHAR(255), description VARCHAR(512), weight FLOAT);"</code></pre>
                    <p>Now, insert a row:</p>
                    <pre><code>docker-compose exec -u postgres postgres psql -d inventory -c "INSERT INTO products (name, description, weight) VALUES ('Laptop', 'A powerful laptop', 1.5);"</code></pre>
                </li>
                 <li>
                    <h3>Observe the Change Event in Kafka</h3>
                    <p>Finally, let's consume from the Kafka topic to see the change event that Debezium generated. The topic name is based on the `database.server.name` and the table name (`dbserver1.public.products`).</p>
                    <pre><code>docker-compose exec kafka kafka-console-consumer --bootstrap-server kafka:29092 --topic dbserver1.public.products --from-beginning --property print.key=true</code></pre>
                    <p>You will see a detailed JSON payload representing the `INSERT` operation you just performed. Congratulations, you've built a working CDC pipeline!</p>
                </li>
            </ol>
        </section>
         <div class="pagination">
        <a href="troubleshooting/">← Back: Troubleshooting</a>
        <a href="quickstarts/">Next: Quick-Start Guides →</a>
      </div>
