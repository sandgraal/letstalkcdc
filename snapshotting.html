<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta content="width=device-width, initial-scale=1" name="viewport" />
    <title>Snapshotting (Initial Load) | CDC: The Missing Manual</title>
    <meta
      content="Learn how to handle the initial data load (snapshotting) in a CDC pipeline consistently and without data loss."
      name="description"
    />
    <link href="styles.css" rel="stylesheet" />
    <link
      rel="canonical"
      href="https://letstalkcdc.nfshost.com/snapshotting.html"
    />

    <!-- SME STYLE START -->
    <style>
      .callout {
        border-left: 4px solid #6b7280;
        padding: 0.75rem 1rem;
        margin: 1rem 0;
        background: #f7f7f7;
      }
      .callout strong {
        color: #111827;
      }
      pre {
        position: relative;
        overflow: auto;
      }
      .copy-btn {
        position: absolute;
        top: 0.4rem;
        right: 0.4rem;
        font: inherit;
        padding: 0.2rem 0.5rem;
        border-radius: 0.5rem;
        border: 1px solid #d1d5db;
        background: #fff;
        cursor: pointer;
      }
      code,
      pre code {
        white-space: pre-wrap;
      }
      section {
        scroll-margin-top: 5rem;
      }
      figure svg {
        max-width: 100%;
        height: auto;
      }
    </style>
    <!-- SME STYLE END -->

    <!-- SME SCRIPT START -->
    <script>
      document.addEventListener(
        "click",
        function (e) {
          if (e.target && e.target.classList.contains("copy-btn")) {
            const pre = e.target.closest("pre");
            if (!pre) return;
            const code = pre.querySelector("code");
            const text = code ? code.innerText : pre.innerText;
            navigator.clipboard.writeText(text).then(() => {
              const old = e.target.textContent;
              e.target.textContent = "Copied";
              setTimeout(() => {
                e.target.textContent = old;
              }, 1200);
            });
          }
        },
        false
      );
    </script>
    <!-- SME SCRIPT END -->
  </head>
  <body>
    <a class="skip-link" href="#main">Skip to content</a>
    <header class="global-header">
      <div class="nav-container">
        <a class="site-title" href="index.html"
          >CDC: The Missing Manual | A Deep Dive into Change Data Capture</a
        >
        <div class="nav-right">
          <nav aria-label="Primary" class="nav-links">
            <a href="index.html">Home</a>
            <a class="active" href="overview.html">The Series</a>
          </nav>
          <button
            aria-label="Toggle dark mode"
            class="theme-toggle"
            data-toggle-theme=""
            type="button"
          >
            🌓
          </button>
        </div>
      </div>
    </header>
    <main class="page-wrap prose" id="main">
      <h1>The First Hurdle: Initial Data Load (Snapshotting)</h1>

      <!-- SME ADDITIONS START: Objectives + Preflight + Per-DB -->
      <section aria-labelledby="obj">
        <h2 id="obj">What you’ll learn</h2>
        <ul>
          <li>Why snapshots need a log high-watermark and idempotent sinks.</li>
          <li>How to choose snapshot modes (initial vs incremental).</li>
          <li>How to size chunks and set parallelism safely.</li>
          <li>How to run a 15-minute lab to prove no gaps/dupes.</li>
          <li>What to monitor and how to recover failures.</li>
        </ul>
      </section>

      <section aria-labelledby="preflight">
        <h2 id="preflight">Pre-flight checklist</h2>
        <ul>
          <li>
            Retention window covers full snapshot duration
            (WAL/binlog/T-log/UNDO).
          </li>
          <li>Privileges for log reading/replication are granted.</li>
          <li>
            Consistent-read isolation is enabled where applicable (e.g.,
            REPEATABLE READ/SNAPSHOT).
          </li>
          <li>
            Sink MERGE/UPSERT implemented; delete/tombstone semantics defined.
          </li>
          <li>Offsets are durable and backed up/versioned.</li>
          <li>DDL freeze or schema-compatibility policy in place.</li>
        </ul>
      </section>

      <section aria-labelledby="perdb">
        <h2 id="perdb">Per-DB: boundary + consistent read (snippets)</h2>

        <details>
          <summary><strong>PostgreSQL</strong></summary>
          <pre><button class="copy-btn" type="button">Copy</button><code>-- Requirements (once/admin):
ALTER SYSTEM SET wal_level = logical;
ALTER SYSTEM SET max_replication_slots = 10;  -- adjust
SELECT pg_reload_conf();

-- Boundary + consistent read (within one tx while snapshotting):
BEGIN TRANSACTION ISOLATION LEVEL REPEATABLE READ;
SELECT pg_current_wal_lsn();  -- record this
-- Keep transaction open during table scans; Debezium coordinates via logical slot.
</code></pre>
        </details>

        <details>
          <summary><strong>MySQL (InnoDB)</strong></summary>
          <pre><button class="copy-btn" type="button">Copy</button><code>-- Requirements:
-- binlog_format=ROW; binlog_row_image=FULL; GTID (preferred)

-- Boundary + consistent snapshot:
SHOW MASTER STATUS;                  -- or SELECT @@global.gtid_executed;
START TRANSACTION WITH CONSISTENT SNAPSHOT;
-- Read tables in PK order; Debezium avoids FTWRL in OLTP paths.
</code></pre>
        </details>

        <details>
          <summary><strong>SQL Server</strong></summary>
          <pre><button class="copy-btn" type="button">Copy</button><code>-- Requirements (once/admin):
ALTER DATABASE YourDb SET ALLOW_SNAPSHOT_ISOLATION ON;
ALTER DATABASE YourDb SET READ_COMMITTED_SNAPSHOT ON;
EXEC sys.sp_cdc_enable_db;  -- if using native CDC

-- Boundary + snapshot:
SELECT sys.fn_cdc_get_max_lsn();     -- record
SET TRANSACTION ISOLATION LEVEL SNAPSHOT;
BEGIN TRAN;
-- Read tables; keep tx open during snapshot.
</code></pre>
        </details>

        <details>
          <summary><strong>Oracle</strong></summary>
          <pre><button class="copy-btn" type="button">Copy</button><code>-- Requirements (once/admin):
ALTER DATABASE ADD SUPPLEMENTAL LOG DATA;  -- minimal or ALL columns for PK-less

-- Boundary:
SELECT CURRENT_SCN FROM V$DATABASE;        -- record
-- Consistent reads use UNDO/flashback; ensure UNDO retention covers snapshot.
</code></pre>
        </details>
      </section>
      <!-- SME ADDITIONS END -->

      <article class="prose">
        <p>
          A CDC pipeline is designed to stream ongoing <em>changes</em>, but it
          must first be initialized with the data that
          <em>already exists</em> in the source tables. This process of
          performing an initial, full copy of the data is known as
          <strong>snapshotting</strong> or the <strong>initial load</strong>.
        </p>

        <h2 id="challenge">The Challenge: Ensuring Consistency</h2>
        <p>
          The central problem of snapshotting is ensuring consistency. How can
          you take a complete copy of a large, active table while new
          transactions are constantly modifying it? A naive approach might miss
          transactions that occur during the snapshot process or, conversely,
          process them twice, once in the snapshot and again in the change
          stream, leading to data duplication or loss.
        </p>

        <h2 id="solution">The Solution: Consistent Snapshots</h2>

        <!-- SME ADDITIONS START: Snapshot→Stream Diagram -->
        <figure aria-label="Snapshot to stream handoff diagram">
          <svg
            viewBox="0 0 760 120"
            width="100%"
            role="img"
            aria-labelledby="handoffTitle"
          >
            <title id="handoffTitle">High-watermark boundary handoff</title>
            <rect
              x="10"
              y="20"
              width="300"
              height="80"
              rx="8"
              fill="currentColor"
              opacity="0.08"
            ></rect>
            <text x="25" y="45" font-size="14">1) Mark high-watermark</text>
            <text x="25" y="70" font-size="12">Record LSN/SCN (boundary)</text>

            <rect
              x="330"
              y="20"
              width="200"
              height="80"
              rx="8"
              fill="currentColor"
              opacity="0.08"
            ></rect>
            <text x="345" y="45" font-size="14">2) Consistent read</text>
            <text x="345" y="70" font-size="12">
              Snapshot tables without gaps
            </text>

            <rect
              x="540"
              y="20"
              width="210"
              height="80"
              rx="8"
              fill="currentColor"
              opacity="0.08"
            ></rect>
            <text x="555" y="45" font-size="14">3) Stream after boundary</text>
            <text x="555" y="70" font-size="12">Apply idempotently</text>

            <line
              x1="310"
              y1="60"
              x2="330"
              y2="60"
              stroke="currentColor"
            ></line>
            <line
              x1="530"
              y1="60"
              x2="540"
              y2="60"
              stroke="currentColor"
            ></line>
            <polygon
              points="330,60 322,56 322,64"
              fill="currentColor"
            ></polygon>
            <polygon
              points="540,60 532,56 532,64"
              fill="currentColor"
            ></polygon>
          </svg>
          <figcaption>
            Snapshot → high-watermark → stream; keep per-key order and
            idempotent sinks.
          </figcaption>
        </figure>
        <!-- SME ADDITIONS END -->

        <p>
          Modern log-based CDC tools like Debezium coordinate a
          <em>point-in-time snapshot</em> with the transaction log so the
          handoff to streaming has no gaps or double-counts. Conceptually:
        </p>
        <ol>
          <li>
            <strong>Mark a high-watermark in the log.</strong> Read and record
            the current log position (LSN/SCN). This is the boundary between
            “history” and “live.”
          </li>
          <li>
            <strong>Take a consistent read of tables.</strong> Use
            snapshot/consistent-read isolation <em>without</em> long blocking
            locks (details vary by database).
          </li>
          <li>
            <strong>Stream changes after the high-watermark.</strong> Consume
            the log from the recorded position; if any changes to rows already
            snapshotted appear, apply <em>idempotently</em> to avoid
            duplication.
          </li>
          <li>
            <strong>Handoff complete.</strong> Snapshot → streaming switch keeps
            per-key order and correctness. Gaps/overlaps are prevented by the
            high-watermark boundary and idempotent upserts at the sink.
          </li>
        </ol>
        <details>
          <summary>
            <strong>How “consistent reads” work (per database)</strong>
          </summary>
          <ul>
            <li>
              <strong>PostgreSQL:</strong> REPEATABLE READ +
              <code>pg_export_snapshot()</code>; logical replication slot sets
              the log boundary. No long blocking table locks, but long snapshots
              can delay VACUUM cleanup (watch bloat).
            </li>
            <li>
              <strong>MySQL/InnoDB:</strong>
              <code>START TRANSACTION WITH CONSISTENT SNAPSHOT</code> + binlog
              position. Debezium avoids
              <code>FLUSH TABLES WITH READ LOCK</code> for OLTP safety.
            </li>
            <li>
              <strong>SQL Server:</strong> CDC tables / log LSN establish the
              boundary; snapshot isolation (or read committed snapshot) enables
              consistent reads.
            </li>
            <li>
              <strong>Oracle:</strong> SCN marks the boundary; read-consistency
              from UNDO provides the snapshot.
            </li>
          </ul>
        </details>

        <h2 id="modes">Snapshot modes (choose intentionally)</h2>
        <ul>
          <li>
            <strong>initial:</strong> Do a snapshot then continue streaming
            (default for first run).
          </li>
          <li>
            <strong>initial_only:</strong> One-time bulk load, no streaming
            (bootstraps batch targets).
          </li>
          <li>
            <strong>schema_only / never:</strong> Skip data snapshot (for
            pre-seeded targets or special cases).
          </li>
          <li>
            <strong>incremental snapshot:</strong> Chunk tables online (no
            global pause) using low/high watermarks and primary-key ranges;
            supports resuming mid-table.
          </li>
        </ul>

        <h2 id="chunking">Performance: chunking &amp; throughput</h2>
        <ul>
          <li>
            <strong>Chunking:</strong> Read large tables in PK-ordered chunks
            (5k–200k rows) to bound memory and reduce long transactions. Prefer
            monotonic PKs; otherwise use synthetic chunking keys.
          </li>
          <li>
            <strong>Parallelism:</strong> Limit concurrent table snapshots to
            protect OLTP (1–3 in parallel).
          </li>
          <li>
            <strong>Throttling:</strong> Use fetch size / max rows per poll to
            keep steady pressure, not bursts.
          </li>
          <li>
            <strong>Replica reads:</strong> For MySQL/PG, consider reading from
            a replica to offload the primary (ensure replication lag is
            acceptable and log positions still align).
          </li>
        </ul>

        <h2 id="ops">Operational guardrails (day-one checks)</h2>
        <ul>
          <li>
            <strong>Log retention:</strong> Ensure WAL/binlog/T-log won’t be
            purged before snapshot finishes. Alert on backlog age and size.
          </li>
          <li>
            <strong>Privileges:</strong> Replication/log-read permissions;
            publication/slot creation where applicable.
          </li>
          <li>
            <strong>DDL during snapshot:</strong> Prefer compatibility rules
            (schema registry) and deploy windows; avoid table rebuilds that
            invalidate consistent reads.
          </li>
          <li>
            <strong>Sink idempotency:</strong> Upsert/delete semantics in the
            warehouse/search index must be idempotent so replays (post-snapshot)
            don’t duplicate data.
          </li>
          <li>
            <strong>Resume safely:</strong> Snapshots should be restartable:
            resume from last completed chunk and the recorded high-watermark.
          </li>
        </ul>
      </article>
      <div class="pagination">
        <a href="intro.html">← Back: Intro to CDC</a>
        <a href="exactly-once.html">Next: Exactly-Once →</a>
      </div>
    </main>
    <footer class="site-footer">
      <p>
        © 2025 Christopher Ennis. A deep dive into the world of Change Data
        Capture.
      </p>
    </footer>
    <script type="module">
      const apply = (m) => (document.documentElement.dataset.theme = m);
      const saved = localStorage.getItem("theme");
      const prefersDark = matchMedia("(prefers-color-scheme: dark)").matches;
      apply(saved ?? (prefersDark ? "dark" : "light"));
      document.addEventListener("click", (e) => {
        if (e.target.matches("[data-toggle-theme]")) {
          const next =
            document.documentElement.dataset.theme === "dark"
              ? "light"
              : "dark";
          apply(next);
          localStorage.setItem("theme", next);
        }
      });
    </script>

    <!-- SME ADDITIONS START: Patterns, Observability, Lab, Gotchas -->
    <section aria-labelledby="idempotent">
      <h2 id="idempotent">Idempotent sink patterns</h2>
      <p>Use UPSERT/MERGE semantics and explicit delete handling.</p>
      <details>
        <summary><strong>Warehouse MERGE example</strong></summary>
        <pre><button class="copy-btn" type="button">Copy</button><code>MERGE INTO dw.customers AS t
USING staging.customers AS s
ON t.customer_id = s.customer_id
WHEN MATCHED THEN UPDATE SET
  name = s.name,
  email = s.email,
  updated_at = s.updated_at
WHEN NOT MATCHED THEN INSERT (customer_id, name, email, updated_at)
VALUES (s.customer_id, s.name, s.email, s.updated_at);</code></pre>
      </details>
      <aside aria-label="Gotcha" class="callout">
        <strong>Gotcha:</strong> Handle deletes explicitly (tombstones or a
        <code>__op</code> field). Otherwise replays produce resurrected rows.
      </aside>
    </section>

    <section aria-labelledby="observability">
      <h2 id="observability">Observability: what to track</h2>
      <ul>
        <li>Source log lag (bytes/time behind) and slot/binlog growth.</li>
        <li>Snapshot throughput (rows/s), chunk duration, ETA by table.</li>
        <li>Sink merge latency and deadlocks.</li>
        <li>Error budget: % chunks retried; time to resume after failure.</li>
      </ul>
    </section>

    <section aria-labelledby="failures">
      <h2 id="failures">Failure modes → actions</h2>
      <ul>
        <li>
          <strong>Long snapshots block VACUUM/UNDO:</strong> shrink chunk size;
          run on a replica; pause between chunks.
        </li>
        <li>
          <strong>Log purged mid-snapshot:</strong> restart from last completed
          chunk; increase retention; consider replica.
        </li>
        <li>
          <strong>No primary key:</strong> define synthetic key or dedupe in
          sink (hash + latest timestamp).
        </li>
        <li>
          <strong>DDL during snapshot:</strong> retry chunk with stable schema;
          versioned views; schema-compat rules.
        </li>
        <li>
          <strong>Replica lag:</strong> validate boundary alignment; if laggy,
          snapshot from primary or temporarily gate OLTP.
        </li>
      </ul>
    </section>

    <section aria-labelledby="lab">
      <h2 id="lab">Hands-on: prove no gaps/dupes (≈15 min)</h2>
      <ol>
        <li>
          Pick your database and run the “boundary + consistent read” snippet.
        </li>
        <li>
          While snapshot runs, perform writes in a second session: insert
          (id=3), update (id=2).
        </li>
        <li>
          After handoff, insert (id=4). Verify sink via MERGE and run a dup
          check.
        </li>
      </ol>
      <details>
        <summary><strong>Dup check query</strong></summary>
        <pre><button class="copy-btn" type="button">Copy</button><code>SELECT id, COUNT(*) AS c
FROM dw.orders
GROUP BY id
HAVING COUNT(*) &gt; 1;</code></pre>
      </details>
    </section>

    <section aria-labelledby="gotchas">
      <h2 id="gotchas">Common gotchas</h2>
      <aside class="callout">
        <strong>Throughput vs safety:</strong> Aim for 5–30s chunk time; keep
        txn duration within retention.
      </aside>
      <aside class="callout">
        <strong>LOBs/wide rows:</strong> Exclude heavy columns from initial
        snapshot; backfill later.
      </aside>
      <aside class="callout">
        <strong>Partitioned tables:</strong> Snapshot partitions in
        deterministic order; beware partition switches.
      </aside>
      <aside class="callout">
        <strong>Time zones:</strong> Normalize to UTC to prevent
        duplicate-by-wall-clock.
      </aside>
    </section>
    <!-- SME ADDITIONS END -->
  </body>
</html>
